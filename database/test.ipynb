{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from embedding.call_embedding import get_embedding\n",
    "from langchain_community.document_loaders import UnstructuredFileLoader\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_chroma.Chroma import Chroma\n",
    "import os\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 首先实现基本配置\n",
    "# DEFAULT_DB_PATH = os.path.join(os.path.abspath(\n",
    "#     __file__), \"../database/knowledge_db\")\n",
    "DEFAULT_DB_PATH = \"./knowledge_db\"\n",
    "# DEFAULT_PERSIST_PATH = os.path.join(os.path.abspath(\n",
    "#     __file__), \"../vector_db\")\n",
    "DEFAULT_PERSIST_PATH = \"../vector_db\"\n",
    "\n",
    "\n",
    "def get_files(dir_path):\n",
    "    file_list = []\n",
    "    for filepath, dirnames, filenames in os.walk(dir_path):\n",
    "        for filename in filenames:\n",
    "            file_list.append(os.path.join(filepath, filename))\n",
    "    return file_list\n",
    "\n",
    "\n",
    "def file_loader(file, loaders):\n",
    "    if isinstance(file, tempfile._TemporaryFileWrapper):\n",
    "        file = file.name\n",
    "    if not os.path.isfile(file):\n",
    "        [file_loader(os.path.join(file, f), loaders) for f in os.listdir(file)]\n",
    "        return\n",
    "    file_type = file.split('.')[-1]\n",
    "    if file_type == 'pdf':\n",
    "        loaders.append(PyMuPDFLoader(file))\n",
    "    elif file_type == 'md':\n",
    "        pattern = r\"不存在|风控\"\n",
    "        match = re.search(pattern, file)\n",
    "        if not match:\n",
    "            loaders.append(UnstructuredMarkdownLoader(file))\n",
    "    elif file_type == 'txt':\n",
    "        loaders.append(UnstructuredFileLoader(file))\n",
    "    return\n",
    "\n",
    "\n",
    "def create_db_info(files=DEFAULT_DB_PATH, embeddings=\"zhipuai\", persist_directory=DEFAULT_PERSIST_PATH):\n",
    "    if files == None:\n",
    "        vectordb = create_db(embeddings=embeddings)\n",
    "    if embeddings == 'openai' or embeddings == 'm3e' or embeddings == 'zhipuai':\n",
    "        vectordb = create_db(files, persist_directory, embeddings)\n",
    "    return f\"{files} create success\"\n",
    "\n",
    "\n",
    "def create_db(files=DEFAULT_DB_PATH, persist_directory=DEFAULT_PERSIST_PATH, embeddings=\"openai\"):\n",
    "    \"\"\"\n",
    "    该函数用于加载 PDF 文件，切分文档，生成文档的嵌入向量，创建向量数据库。\n",
    "\n",
    "    参数:\n",
    "    file: 存放文件的路径。\n",
    "    embeddings: 用于生产 Embedding 的模型\n",
    "\n",
    "    返回:\n",
    "    vectordb: 创建的数据库。\n",
    "    \"\"\"\n",
    "    if files == None:\n",
    "        return \"can't load empty dir\"\n",
    "    if type(files) != list:\n",
    "        files = [files]\n",
    "    loaders = []\n",
    "    [file_loader(file, loaders) for file in files]\n",
    "    docs = []\n",
    "    for loader in loaders:\n",
    "        if loader is not None:\n",
    "            docs.extend(loader.load())\n",
    "    # 切分文档\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500, chunk_overlap=150)\n",
    "    split_docs = text_splitter.split_documents(docs)\n",
    "    if type(embeddings) == str:\n",
    "        embeddings = get_embedding(embedding=embeddings)\n",
    "    # 加载数据库\n",
    "    vectordb = Chroma.from_documents(\n",
    "        documents=split_docs,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=persist_directory  # 允许我们将persist_directory目录保存到磁盘上\n",
    "    )\n",
    "\n",
    "    return vectordb\n",
    "\n",
    "\n",
    "def presit_knowledge_db(vectordb):\n",
    "    \"\"\"\n",
    "    该函数用于持久化向量数据库。\n",
    "\n",
    "    参数:\n",
    "    vectordb: 要持久化的向量数据库。\n",
    "    \"\"\"\n",
    "    vectordb.persist()\n",
    "\n",
    "\n",
    "def load_knowledge_db(path=DEFAULT_PERSIST_PATH, embeddings=\"m3e\"):\n",
    "    \"\"\"\n",
    "    该函数用于加载向量数据库。\n",
    "\n",
    "    参数:\n",
    "    path: 要加载的向量数据库路径。\n",
    "    embeddings: 向量数据库使用的 embedding 模型。\n",
    "\n",
    "    返回:\n",
    "    vectordb: 加载的数据库。\n",
    "    \"\"\"\n",
    "    vectordb = Chroma(\n",
    "        persist_directory=path,\n",
    "        embedding_function=embeddings\n",
    "    )\n",
    "    return vectordb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = create_db(files=get_files(\"./knowledge_db\"), embeddings=\"m3e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"向量库中存储的数量：{vectordb._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"色彩\"\n",
    "sim_docs = vectordb.similarity_search(question,k=10)\n",
    "print(f\"检索到的内容数：{len(sim_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sim_doc in enumerate(sim_docs):\n",
    "    print(f\"检索到的第{i}个内容: \\n{sim_doc.page_content}\", end=\"\\n--------------\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-chat-policy-model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
